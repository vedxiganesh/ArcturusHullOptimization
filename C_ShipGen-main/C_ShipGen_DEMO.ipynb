{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-ShipGen: Sample Tailored Ship Hulls from a Tabular DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Up Tasks: Don't alter Please #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the fun\n",
    "import sys\n",
    "import os \n",
    "sys.path.append('./tools')\n",
    "sys.path.append('./data')\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import Guided_Cond_DDPM_Tools as GC_DDPM\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from HullParameterization import Hull_Parameterization as HP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True) # don't use scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82168, 45)\n",
      "(82793, 44)\n",
      "(44, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load in the Data:\n",
    "\n",
    "#Step 1: Load in the data\n",
    "DesVec = np.load('./data/DesVec_82k.npy', allow_pickle=True)\n",
    "print(DesVec.shape)\n",
    "\n",
    "DesVec_neg = np.load('./data/Negative_DesVec_82k.npy', allow_pickle=True)\n",
    "print(DesVec_neg.shape)\n",
    "\n",
    "\n",
    "# Now lets clean up X\n",
    "\n",
    "idx_BBFactors = [33,34,35,36,37]\n",
    "idx_BB = 31\n",
    "\n",
    "idx_SBFactors = [38,39,40,41,42,43,44]\n",
    "idx_SB = 32\n",
    "\n",
    "for i in range(0,len(DesVec)):\n",
    "    \n",
    "    DesVec[i,idx_BBFactors] = DesVec[i,idx_BB] * DesVec[i,idx_BBFactors] \n",
    "    DesVec[i,idx_SBFactors] = DesVec[i,idx_SB] * DesVec[i,idx_SBFactors]\n",
    "\n",
    "\n",
    "\n",
    "Y = np.load('./data/GeometricMeasures.npy', allow_pickle=True)\n",
    "\n",
    "LenRatios = np.load('./data/Length_Ratios.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "X_LIMITS = np.load('./data/X_LIMITS.npy')\n",
    "\n",
    "print(X_LIMITS.shape)\n",
    "\n",
    "X_lower_lim = [X_LIMITS[:,0].tolist()]                   \n",
    "X_upper_lim = [X_LIMITS[:,1].tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([77257, 77257, 77257, 77257], dtype=int64), array([1, 2, 3, 4], dtype=int64))\n",
      "(82168, 101)\n",
      "(82168,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgnau\\AppData\\Local\\Temp\\ipykernel_26836\\214063027.py:4: RuntimeWarning: invalid value encountered in log10\n",
      "  VolVec = np.log10(Y[:,1*num_WL_Steps:2*num_WL_Steps])\n"
     ]
    }
   ],
   "source": [
    "#Set up Conditioning Vectors:\n",
    "num_WL_Steps = 101\n",
    "\n",
    "VolVec = np.log10(Y[:,1*num_WL_Steps:2*num_WL_Steps])\n",
    "idx = np.where(np.isnan(VolVec))\n",
    "print(idx)\n",
    "\n",
    "VolVec[idx] = -6.0 #fix nan to dummy value\n",
    "\n",
    "print(VolVec.shape)\n",
    "\n",
    "DdVec = DesVec[:,4]\n",
    "BOAVec = np.amax(LenRatios[:,1:3], axis=1)\n",
    "print(BOAVec.shape) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file for architecting the network, diffusion parameters, and training\n",
    "\n",
    "DDPM_Dict = {\n",
    "        'xdim' : len(DesVec[0])-1,             # Dimension of parametric design vector\n",
    "        'datalength': len(DesVec),           # number of samples\n",
    "        'X_LL' : X_lower_lim,           # lower limits of parametric design vector variables\n",
    "        'X_UL' : X_upper_lim,\n",
    "        'ydim': 0,                       # Number of objectives\n",
    "        'cdim': 4,                      # number of conditioning inputs\n",
    "        'gamma' : 0.2,                  # weight of feasibility guidance for guided sampling\n",
    "        'lambda': [0.3,0.3],                 # weight of drag  guidance for guided sampling\n",
    "        #'lambdas': [1,1,1,1,1,1,1],     # dummy variable for performance guided sampling\n",
    "        'tdim': 128,                    # dimension of latent variable\n",
    "        'net': [1024,1024,1024,1024],   # network architecture\n",
    "        'batch_size': 1024,             # batch size\n",
    "        'Training_Epochs': 10000,      # number of training epochs\n",
    "        'Diffusion_Timesteps': 1000,    # number of diffusion timesteps\n",
    "        'lr' : 0.00025,                 # learning rate\n",
    "        'weight_decay': 0.0,            # weight decay\n",
    "        'device_name': device}        # gpu device name\n",
    "\n",
    "\n",
    "Classify_Dict = {\n",
    "        'xdim' : len(DesVec[0])-1,\n",
    "        'cdim': 1,\n",
    "        'tdim': 128,\n",
    "        'net': [64,64,64],\n",
    "        'Training_Epochs': 150000,\n",
    "        'device_name': device}\n",
    "\n",
    "nodes = 512\n",
    "Drag_Reg_Dict = {\n",
    "        'xdim' : len(DesVec[0])-1,              # Dimension of parametric design vector\n",
    "        'ydim': 1,                              # trains regression model for each objective\n",
    "        'tdim': nodes,                            # dimension of latent variable\n",
    "        'net': [nodes,nodes,nodes,nodes],                       # network architecture        \n",
    "        'Training_Epochs': 50000,  #30000             # number of training epochs\n",
    "        'batch_size': 1024,                       # batch size\n",
    "        'Model_Label': 'Regressor_CT',         # labels for regressors       \n",
    "        'lr' : 0.001,                          # learning rate\n",
    "        'weight_decay': 0.0,                   # weight decay\n",
    "        'device_name': device} \n",
    "\n",
    "nodes = 256\n",
    "LOA_wBulb_Reg_Dict = {\n",
    "        'xdim' : len(DesVec[0])-1,              # Dimension of parametric design vector\n",
    "        'ydim': 1,                              # trains regression model for each objective\n",
    "        'tdim': nodes,                            # dimension of latent variable\n",
    "        'net': [nodes,nodes,nodes],                       # network architecture        \n",
    "        'Training_Epochs': 150000,               # number of training epochs\n",
    "        'batch_size': 1024,                       # batch size\n",
    "        'Model_Label': 'Regressor_LOA_wBulb',         # labels for regressors\n",
    "                    \n",
    "        'lr' : 0.001,                          # learning rate\n",
    "        'weight_decay': 0.0,                   # weight decay\n",
    "        'device_name': device}   \n",
    "\n",
    "WL_Reg_Dict = {\n",
    "        \"xdim\": len(DesVec[0]),\n",
    "        \"ydim\": 1, \n",
    "        \"tdim\": 512, \n",
    "        \"net\": [512, 512, 512], \n",
    "        \"Training_Epochs\": 30000, \n",
    "        \"batch_size\": 1024, \n",
    "        \"Model_Label\": \n",
    "        \"Regressor_WL\", \n",
    "        \"lr\": 0.001, \n",
    "        \"weight_decay\": 0.0, \n",
    "        \"device_name\": device}\n",
    "\n",
    "Vol_Reg_Dict = {\n",
    "                \"xdim\": len(DesVec[0]), \n",
    "                \"ydim\": 1, \n",
    "                \"tdim\": 512, \n",
    "                \"net\": [512, 512, 512], \n",
    "                \"Training_Epochs\": 30000, \n",
    "                \"batch_size\": 1024, \n",
    "                \"Model_Label\": \"Regressor_WL\", \n",
    "                \"lr\": 0.001, \n",
    "                \"weight_decay\": 0.0, \n",
    "                \"device_name\": device}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "T = GC_DDPM.GuidedDiffusionEnv(DDPM_Dict,\n",
    "                Classify_Dict,\n",
    "                Drag_Reg_Dict,\n",
    "                LOA_wBulb_Reg_Dict,\n",
    "                WL_Reg_Dict,\n",
    "                Vol_Reg_Dict,\n",
    "                X= DesVec[:,1:],\n",
    "                X_neg= DesVec_neg,\n",
    "                VolVec = VolVec, \n",
    "                BOAVec = BOAVec, \n",
    "                DdVec = DdVec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(PATH, map_location=self.device))\n",
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.classifier.load_state_dict(torch.load(PATH, map_location=self.device))\n",
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.Drag_Reg.load_state_dict(torch.load(PATH[0],map_location=self.device))\n",
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.LOA_wBulb_Reg.load_state_dict(torch.load(PATH[1],map_location=self.device))\n",
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.WL_Reg.load_state_dict(torch.load(PATH[2],map_location=self.device))\n",
      "c:\\Users\\vgnau\\Documents\\ArcturusHullOptimization\\C_ShipGen-main\\tools\\Guided_Cond_DDPM_Tools.py:1235: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.Vol_Reg.load_state_dict(torch.load(PATH[3],map_location=self.device))\n"
     ]
    }
   ],
   "source": [
    "diffusion_path = './TrainedModels/CShipGen_diffusion.pth'\n",
    "T.load_trained_diffusion_model(diffusion_path)\n",
    "\n",
    "classifier_path = './TrainedModels/Constraint_Classifier_150000Epochs.pth' \n",
    "\n",
    "T.load_trained_classifier_model(classifier_path)\n",
    "\n",
    "\n",
    "PATHS = ['./TrainedModels/Regressor_CT.pth',\n",
    "        './TrainedModels/Regressor_LOA_wBulb.pth',\n",
    "        './TrainedModels/Regressor_WL.pth',\n",
    "        './TrainedModels/Regressor_Vol.pth']\n",
    "\n",
    "\n",
    "T.load_trained_Drag_regression_models(PATHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Ship's Principal Characteristics ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample from the Model:\n",
    "num_samples = 100\n",
    "\n",
    "Ship = np.array([1.22, .25, .127, .254 , .019,1.4]) #[LOA(m), Beam(m), Draft(m), Depth(m), Volume(m^3), U(m/s)] # This is for an aircraft carrier dimensioned ship\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Hulls using C-ShipGen ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Hulls\n",
      "(100, 3)\n",
      "(100, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967/967 [00:22<00:00, 43.85it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 253.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 45)\n",
      "Predicted Mean Drag of Guidance samples: 11.134827 N\n",
      "Minimum Drag of Guidance samples: 0.51811755 N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the Loop on the other samples:\n",
    "\n",
    "print('Generating Hulls')\n",
    "\n",
    "LOA = Ship[0] #in meters\n",
    "BoL = Ship[1]/LOA #beam to length ratio\n",
    "ToD = Ship[2]/Ship[3] #Draft to depth ratio\n",
    "DoL = Ship[3]/LOA #Depth to length ratio\n",
    "Vol = np.log10(Ship[4]/LOA**3) # to normalize Volume by LOA**3\n",
    "\n",
    "U = Ship[5]  #  12.86 #m/s  = 25 knots\n",
    "\n",
    "dim_d = np.array([[ToD, U, LOA]]) #Drag_conditioning is [ToD, U(m/s), LOA (m)]\n",
    "\n",
    "drag_cond = np.repeat(dim_d, num_samples, axis=0) #reapeat \n",
    "print(drag_cond.shape)\n",
    "dim_g = np.array([[ToD, BoL, DoL, Vol]])\n",
    "\n",
    "geom_cond = np.repeat(dim_g, num_samples, axis=0) #reapeat \n",
    "print(geom_cond.shape)\n",
    "\n",
    "X_gen, unnorm = T.gen_vol_drag_guided_samples(geom_cond, drag_cond)\n",
    "\n",
    "print(X_gen.shape)\n",
    "\n",
    "\n",
    "Rt_guidance = T.Predict_Drag(unnorm, drag_cond)\n",
    "Drag_Guidance = np.mean(Rt_guidance)\n",
    "\n",
    "\n",
    "print('Predicted Mean Drag of Guidance samples: ' + str(Drag_Guidance) + ' N')\n",
    "print('Minimum Drag of Guidance samples: ' + str(np.amin(Rt_guidance)) + ' N')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the Vectors and Check Feasibility ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Feasibility of Samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 7508.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(valid_idx))\\nsample_vol = []\\nsample_BOA = []\\nsample_Dd = []\\nsample_LOA = []\\nsample_LOA_wBulb = []\\nidx_to_remove = []\\n\\nfor i in tqdm(range(0,len(valid_idx))):\\n    hull = HP(x_samples[valid_idx[i]]) \\n    #print(i)\\n    try:\\n        Z = hull.Calc_VolumeProperties(NUM_WL = 101, PointsPerWL = 1000)    \\n        sample_vol.append(HP.interp(hull.Volumes, Z, Ship[2])) #interpolate to the draft of the ship\\n        BOA = max(hull.Calc_Max_Beam_midship(), hull.Calc_Max_Beam_PC())\\n        sample_BOA.append(BOA)\\n        sample_Dd.append(hull.Dd)\\n        sample_LOA.append(hull.LOA)\\n        sample_LOA_wBulb.append(hull.Calc_LOA_wBulb())\\n    except:\\n        print('error at hull {}'.format(i))\\n        idx_to_remove.append(i)\\n\\n        continue\\n\\n#Remove the samples that failed to calculate volume properties\\nvalid_idx = np.delete(valid_idx, idx_to_remove)\\nprint(len(valid_idx))\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_samples = X_gen\n",
    "\n",
    "#print(x_samples[0:3])\n",
    "    \n",
    "print('Checking Feasibility of Samples')\n",
    "\n",
    "for i in range(0,len(x_samples)):\n",
    "    \n",
    "    x_samples[i,idx_BB] = (x_samples[i,idx_BB] + 0.5) // 1 #int rounds to 1 or 0\n",
    "    x_samples[i,idx_SB] = (x_samples[i,idx_SB] + 0.5) // 1 #int rounds to 1 or 0\n",
    "    \n",
    "    \n",
    "    x_samples[i,idx_BBFactors] = x_samples[i,idx_BB] * x_samples[i,idx_BBFactors] \n",
    "    x_samples[i,idx_SBFactors] = x_samples[i,idx_SB] * x_samples[i,idx_SBFactors]\n",
    "\n",
    "\n",
    "\n",
    "#Check the constraint violations for the sampled designs\n",
    "constraints = []\n",
    "sum_violation = []\n",
    "cons = []\n",
    "valid_idx = []\n",
    "\n",
    "for i in tqdm(range(0,len(x_samples))):\n",
    "    hull = HP(x_samples[i])\n",
    "    constraints.append(hull.input_Constraints())\n",
    "    cons.append(constraints[i] > 0)\n",
    "    if sum(cons[i]) == 0:\n",
    "        valid_idx.append(i)\n",
    "        #hull.Calc_VolumeProperties(NUM_WL = 101, PointsPerWL = 1000)\n",
    "    sum_violation.append(sum(cons[i]))\n",
    "\n",
    "'''\n",
    "print(len(valid_idx))\n",
    "sample_vol = []\n",
    "sample_BOA = []\n",
    "sample_Dd = []\n",
    "sample_LOA = []\n",
    "sample_LOA_wBulb = []\n",
    "idx_to_remove = []\n",
    "\n",
    "for i in tqdm(range(0,len(valid_idx))):\n",
    "    hull = HP(x_samples[valid_idx[i]]) \n",
    "    #print(i)\n",
    "    try:\n",
    "        Z = hull.Calc_VolumeProperties(NUM_WL = 101, PointsPerWL = 1000)    \n",
    "        sample_vol.append(HP.interp(hull.Volumes, Z, Ship[2])) #interpolate to the draft of the ship\n",
    "        BOA = max(hull.Calc_Max_Beam_midship(), hull.Calc_Max_Beam_PC())\n",
    "        sample_BOA.append(BOA)\n",
    "        sample_Dd.append(hull.Dd)\n",
    "        sample_LOA.append(hull.LOA)\n",
    "        sample_LOA_wBulb.append(hull.Calc_LOA_wBulb())\n",
    "    except:\n",
    "        print('error at hull {}'.format(i))\n",
    "        idx_to_remove.append(i)\n",
    "\n",
    "        continue\n",
    "\n",
    "#Remove the samples that failed to calculate volume properties\n",
    "valid_idx = np.delete(valid_idx, idx_to_remove)\n",
    "print(len(valid_idx))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Stl of valid Hull Designs ###\n",
    "\n",
    "Note: \n",
    "\n",
    "Not all generated samples are feasible since C-ShipGen is a statistical Model.\n",
    "\n",
    "Similarly, C-ShipGen does not generate hull designs exactly to the dimensions specified by the user; however, these designs are close to the intended dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designs with Minimum Drag: \n",
      "Demo_Hull_85\n",
      "Demo_Hull_43\n",
      "Demo_Hull_20\n",
      "Demo_Hull_69\n",
      "Demo_Hull_89\n",
      "Demo_Hull_23\n",
      "Demo_Hull_2\n",
      "Demo_Hull_91\n",
      "Demo_Hull_9\n",
      "Demo_Hull_39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Predicted Drag: 7.5563607 N\n",
      "Design with Minimum Predicted Drag: \n",
      "Demo_Hull_85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"./DEMO_Hulls/\"\n",
    "\n",
    "label = 'Demo_Hull_'\n",
    "\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "\n",
    "# print the indices of the 10 hulls with the lowest drag\n",
    "print('Designs with Minimum Drag: ')\n",
    "idxs = np.argsort(Rt_guidance[valid_idx].flatten())\n",
    "for i in range(10):\n",
    "    print(label + str(valid_idx[idxs[i]]))\n",
    "    #save parameters of designs with minimum drag\n",
    "with open('Min_Drag_Hull_Parameters.pkl', 'wb') as f:\n",
    "    pickle.dump(x_samples[idxs[0:10]], f)\n",
    "    \n",
    "\n",
    "for i in tqdm(range(0,10)):\n",
    "    Hull = HP(x_samples[valid_idx[idxs[i]]])\n",
    "    #make the .stl file of the hull:\n",
    "    strpath =  path+label + '_' + str(valid_idx[idxs[i]])\n",
    "    try:\n",
    "        mesh = Hull.gen_stl(NUM_WL=47, PointsPerWL=151, bit_AddTransom = 1, bit_AddDeckLid = 1, bit_RefineBowAndStern = 1,namepath = strpath)\n",
    "    except:\n",
    "        print('Error at hull {}'.format(valid_idx[idxs[i]]))\n",
    "\n",
    "idx_min_pred_drag = np.argmin(Rt_guidance[valid_idx])\n",
    "print('Minimum Predicted Drag: ' + str(Rt_guidance[valid_idx][idx_min_pred_drag][0]) + ' N')\n",
    "print('Design with Minimum Predicted Drag: ')\n",
    "print(label + str(valid_idx[idx_min_pred_drag])) #Highlight design with minimum predicted drag\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLabels = ['Low', 'Medium', 'High']\\nWL = [47, 111, 203]\\nPPW = [151, 301, 601]\\n\\nidx = 87\\n\\nfor i in tqdm(range(len(Labels))):\\n    Hull = HP(x_samples[idx])\\n    #make the .stl file of the hull:\\n    strpath =  path+label + '_' + str(idx) + '_' + Labels[i]\\n    try:\\n        mesh = Hull.gen_stl(NUM_WL=WL[i], PointsPerWL=PPW[i], bit_AddTransom = 1, bit_AddDeckLid = 1, bit_RefineBowAndStern = 1,namepath = strpath)\\n    except:\\n        print('Error at hull {}'.format(valid_idx[idxs[i]]))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design a hull with multiple fidelity levels\n",
    "'''\n",
    "Labels = ['Low', 'Medium', 'High']\n",
    "WL = [47, 111, 203]\n",
    "PPW = [151, 301, 601]\n",
    "\n",
    "idx = 87\n",
    "\n",
    "for i in tqdm(range(len(Labels))):\n",
    "    Hull = HP(x_samples[idx])\n",
    "    #make the .stl file of the hull:\n",
    "    strpath =  path+label + '_' + str(idx) + '_' + Labels[i]\n",
    "    try:\n",
    "        mesh = Hull.gen_stl(NUM_WL=WL[i], PointsPerWL=PPW[i], bit_AddTransom = 1, bit_AddDeckLid = 1, bit_RefineBowAndStern = 1,namepath = strpath)\n",
    "    except:\n",
    "        print('Error at hull {}'.format(valid_idx[idxs[i]]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Predicted Drag of Test Hull: 12658722.0 N\n"
     ]
    }
   ],
   "source": [
    "# Compare to Test Hull:\n",
    "\n",
    "design = [[333,\t0.587059958,\t0.409996119,\t0.122972918,\t0.085,\t0.71417088,\t0.211,\t0.120262544,\t10.70168725,\t0.264897988,\t0.961214759,\t-0.27,\t0.15,\t0.01,\t0.3,\t2.172250534,\t-2.220618947,\t0,\t0.1,\t0.05,\t0,\t0,\t0.104249968,\t0.37043854,\t0.006300723,\t-2.478684046,\t2.882864263,\t3.320624286,\t0.076330577,\t0.48538725,\t0.455186006,\t1,\t1,\t0.01,\t0.4,\t0.17155627,\t0.38035235,\t0.269331342,\t0.7,\t0.01,\t1,\t0.7,\t0.025,\t0.99,\t0.147764723]]\n",
    "\n",
    "print(len(design[0]))\n",
    "\n",
    "hull = HP(design[0])\n",
    "\n",
    "strpath =  path+'Test_Hull_Nimitz'\n",
    "mesh = hull.gen_stl(NUM_WL=47, PointsPerWL=151, bit_AddTransom = 1, bit_AddDeckLid = 1, bit_RefineBowAndStern = 1,namepath = strpath)\n",
    "\n",
    "unnormed_des = T.data_norm.transform_Data(design[0][1:])\n",
    "#unnormed_des = torch.from_numpy(unnormed_des.astype('float32'))\n",
    "\n",
    "Rt_Test = T.Predict_Drag(unnormed_des, drag_cond[0:1])\n",
    "\n",
    "print('Predicted Drag of Test Hull: ' + str(Rt_Test[0,0]) + ' N')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "24b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
